{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.poincare import PoincareModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/master_thesis/mapping/data_ready_to_use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id</th>\n",
       "      <th>concept_name</th>\n",
       "      <th>concept_synonym_name</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>preprocessed_synonyms</th>\n",
       "      <th>preprocessed_without_stemming</th>\n",
       "      <th>preprocessed_synonyms_without_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4001098</td>\n",
       "      <td>Radiating chest pain</td>\n",
       "      <td>Radiating chest pain (finding)</td>\n",
       "      <td>radiat chest pain</td>\n",
       "      <td>radiat chest pain find</td>\n",
       "      <td>radiating chest pain</td>\n",
       "      <td>radiating chest pain finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37392117</td>\n",
       "      <td>Urine tryptophan:creatinine ratio</td>\n",
       "      <td>Urine tryptophan:creatinine ratio (observable ...</td>\n",
       "      <td>urin tryptophan creatinin ratio</td>\n",
       "      <td>urin tryptophan creatinin ratio observ entiti</td>\n",
       "      <td>urine tryptophan creatinine ratio</td>\n",
       "      <td>urine tryptophan creatinine ratio observable e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37398455</td>\n",
       "      <td>Urine threonine:creatinine ratio</td>\n",
       "      <td>Urine threonine:creatinine ratio (observable e...</td>\n",
       "      <td>urin threonin creatinin ratio</td>\n",
       "      <td>urin threonin creatinin ratio observ entiti</td>\n",
       "      <td>urine threonine creatinine ratio</td>\n",
       "      <td>urine threonine creatinine ratio observable en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37392118</td>\n",
       "      <td>Urine taurine:creatinine ratio</td>\n",
       "      <td>Urine taurine:creatinine ratio (observable ent...</td>\n",
       "      <td>urin taurin creatinin ratio</td>\n",
       "      <td>urin taurin creatinin ratio observ entiti</td>\n",
       "      <td>urine taurine creatinine ratio</td>\n",
       "      <td>urine taurine creatinine ratio observable entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37392119</td>\n",
       "      <td>Urine phenylalanine:creatinine ratio</td>\n",
       "      <td>Urine phenylalanine:creatinine ratio (observab...</td>\n",
       "      <td>urin phenylalanin creatinin ratio</td>\n",
       "      <td>urin phenylalanin creatinin ratio observ entiti</td>\n",
       "      <td>urine phenylalanine creatinine ratio</td>\n",
       "      <td>urine phenylalanine creatinine ratio observabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491491</th>\n",
       "      <td>37398450</td>\n",
       "      <td>Urine homocysteine:creatinine ratio</td>\n",
       "      <td>Urine homocysteine:creatinine ratio (observabl...</td>\n",
       "      <td>urin homocystein creatinin ratio</td>\n",
       "      <td>urin homocystein creatinin ratio observ entiti</td>\n",
       "      <td>urine homocysteine creatinine ratio</td>\n",
       "      <td>urine homocysteine creatinine ratio observable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491492</th>\n",
       "      <td>37398451</td>\n",
       "      <td>Urine aspartate:creatinine ratio</td>\n",
       "      <td>Urine aspartate:creatinine ratio (observable e...</td>\n",
       "      <td>urin aspart creatinin ratio</td>\n",
       "      <td>urin aspart creatinin ratio observ entiti</td>\n",
       "      <td>urine aspartate creatinine ratio</td>\n",
       "      <td>urine aspartate creatinine ratio observable en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491493</th>\n",
       "      <td>37398452</td>\n",
       "      <td>Urine alanine:creatinine ratio</td>\n",
       "      <td>Urine alanine:creatinine ratio (observable ent...</td>\n",
       "      <td>urin alanin creatinin ratio</td>\n",
       "      <td>urin alanin creatinin ratio observ entiti</td>\n",
       "      <td>urine alanine creatinine ratio</td>\n",
       "      <td>urine alanine creatinine ratio observable entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491494</th>\n",
       "      <td>37398453</td>\n",
       "      <td>Urine valine:creatinine ratio</td>\n",
       "      <td>Urine valine:creatinine ratio (observable entity)</td>\n",
       "      <td>urin valin creatinin ratio</td>\n",
       "      <td>urin valin creatinin ratio observ entiti</td>\n",
       "      <td>urine valine creatinine ratio</td>\n",
       "      <td>urine valine creatinine ratio observable entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491495</th>\n",
       "      <td>37398454</td>\n",
       "      <td>Urine tyrosine:creatinine ratio</td>\n",
       "      <td>Urine tyrosine:creatinine ratio (observable en...</td>\n",
       "      <td>urin tyrosin creatinin ratio</td>\n",
       "      <td>urin tyrosin creatinin ratio observ entiti</td>\n",
       "      <td>urine tyrosine creatinine ratio</td>\n",
       "      <td>urine tyrosine creatinine ratio observable entity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491496 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        concept_id                          concept_name   \n",
       "0          4001098                  Radiating chest pain  \\\n",
       "1         37392117     Urine tryptophan:creatinine ratio   \n",
       "2         37398455      Urine threonine:creatinine ratio   \n",
       "3         37392118        Urine taurine:creatinine ratio   \n",
       "4         37392119  Urine phenylalanine:creatinine ratio   \n",
       "...            ...                                   ...   \n",
       "491491    37398450   Urine homocysteine:creatinine ratio   \n",
       "491492    37398451      Urine aspartate:creatinine ratio   \n",
       "491493    37398452        Urine alanine:creatinine ratio   \n",
       "491494    37398453         Urine valine:creatinine ratio   \n",
       "491495    37398454       Urine tyrosine:creatinine ratio   \n",
       "\n",
       "                                     concept_synonym_name   \n",
       "0                          Radiating chest pain (finding)  \\\n",
       "1       Urine tryptophan:creatinine ratio (observable ...   \n",
       "2       Urine threonine:creatinine ratio (observable e...   \n",
       "3       Urine taurine:creatinine ratio (observable ent...   \n",
       "4       Urine phenylalanine:creatinine ratio (observab...   \n",
       "...                                                   ...   \n",
       "491491  Urine homocysteine:creatinine ratio (observabl...   \n",
       "491492  Urine aspartate:creatinine ratio (observable e...   \n",
       "491493  Urine alanine:creatinine ratio (observable ent...   \n",
       "491494  Urine valine:creatinine ratio (observable entity)   \n",
       "491495  Urine tyrosine:creatinine ratio (observable en...   \n",
       "\n",
       "                             preprocessed   \n",
       "0                       radiat chest pain  \\\n",
       "1         urin tryptophan creatinin ratio   \n",
       "2           urin threonin creatinin ratio   \n",
       "3             urin taurin creatinin ratio   \n",
       "4       urin phenylalanin creatinin ratio   \n",
       "...                                   ...   \n",
       "491491   urin homocystein creatinin ratio   \n",
       "491492        urin aspart creatinin ratio   \n",
       "491493        urin alanin creatinin ratio   \n",
       "491494         urin valin creatinin ratio   \n",
       "491495       urin tyrosin creatinin ratio   \n",
       "\n",
       "                                  preprocessed_synonyms   \n",
       "0                                radiat chest pain find  \\\n",
       "1         urin tryptophan creatinin ratio observ entiti   \n",
       "2           urin threonin creatinin ratio observ entiti   \n",
       "3             urin taurin creatinin ratio observ entiti   \n",
       "4       urin phenylalanin creatinin ratio observ entiti   \n",
       "...                                                 ...   \n",
       "491491   urin homocystein creatinin ratio observ entiti   \n",
       "491492        urin aspart creatinin ratio observ entiti   \n",
       "491493        urin alanin creatinin ratio observ entiti   \n",
       "491494         urin valin creatinin ratio observ entiti   \n",
       "491495       urin tyrosin creatinin ratio observ entiti   \n",
       "\n",
       "               preprocessed_without_stemming   \n",
       "0                       radiating chest pain  \\\n",
       "1          urine tryptophan creatinine ratio   \n",
       "2           urine threonine creatinine ratio   \n",
       "3             urine taurine creatinine ratio   \n",
       "4       urine phenylalanine creatinine ratio   \n",
       "...                                      ...   \n",
       "491491   urine homocysteine creatinine ratio   \n",
       "491492      urine aspartate creatinine ratio   \n",
       "491493        urine alanine creatinine ratio   \n",
       "491494         urine valine creatinine ratio   \n",
       "491495       urine tyrosine creatinine ratio   \n",
       "\n",
       "                   preprocessed_synonyms_without_stemming  \n",
       "0                            radiating chest pain finding  \n",
       "1       urine tryptophan creatinine ratio observable e...  \n",
       "2       urine threonine creatinine ratio observable en...  \n",
       "3        urine taurine creatinine ratio observable entity  \n",
       "4       urine phenylalanine creatinine ratio observabl...  \n",
       "...                                                   ...  \n",
       "491491  urine homocysteine creatinine ratio observable...  \n",
       "491492  urine aspartate creatinine ratio observable en...  \n",
       "491493   urine alanine creatinine ratio observable entity  \n",
       "491494    urine valine creatinine ratio observable entity  \n",
       "491495  urine tyrosine creatinine ratio observable entity  \n",
       "\n",
       "[491496 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhraseEmbeddingDataset(Dataset):\n",
    "    def __init__(self, X, y, w2v_model, poincare_model, max_len=20):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w2v_model = w2v_model\n",
    "        self.poincare_model = poincare_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get Word2Vec embedding\n",
    "        X = self.get_phrase_vector(self.X.iloc[idx], self.w2v_model, self.max_len)\n",
    "        \n",
    "        # Get Poincare embedding\n",
    "        y = torch.tensor(self.poincare_model.kv[self.y.iloc[idx]], dtype=torch.float)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    @staticmethod\n",
    "    def get_phrase_vector(phrase, model, max_len):\n",
    "        words = str(phrase).split()\n",
    "        phrase_vector = np.zeros((max_len, model.vector_size))\n",
    "\n",
    "        for i in range(max_len):\n",
    "            if i < len(words) and words[i] in model.wv:\n",
    "                phrase_vector[i] = model.wv[words[i]]\n",
    "\n",
    "        phrase_vector = phrase_vector.flatten()\n",
    "        \n",
    "        return torch.tensor(phrase_vector, dtype=torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(\"/workspaces/master_thesis/word2vec_pubmed.model\")\n",
    "poincare_model = PoincareModel.load('/workspaces/master_thesis/poincare_100d_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your phrases into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['preprocessed_synonyms_without_stemming'], df['preprocessed'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create your datasets\n",
    "train_dataset = PhraseEmbeddingDataset(X_train, y_train, w2v_model, poincare_model)\n",
    "test_dataset = PhraseEmbeddingDataset(X_test, y_test, w2v_model, poincare_model)\n",
    "\n",
    "# Create your data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  # 2 for bidirection\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape the input to (batch_size, seq_len, features)\n",
    "        x = x.view(x.size(0), 20, 300)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(input_size=300, hidden_size=300, output_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/6144], Loss: 0.0071\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyporbolic_distance(x,y):\n",
    "    #calculate hyporbolic distance between two vectors\n",
    "    return np.arccosh(1 + 2 * np.linalg.norm(x-y)**2 / ((1 - np.linalg.norm(x)**2) * (1 - np.linalg.norm(y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1670392/2664624457.py:3: RuntimeWarning: invalid value encountered in arccosh\n",
      "  return np.arccosh(1 + 2 * np.linalg.norm(x-y)**2 / ((1 - np.linalg.norm(x)**2) * (1 - np.linalg.norm(y)**2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=1: 15.828077314343844%\n",
      "Accuracy for k=5: 34.91353001017294%\n",
      "Accuracy for k=10: 53.097660223804674%\n",
      "Accuracy for k=20: 70.43336724313326%\n",
      "Accuracy for k=50: 96.91556459816887%\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "model = BiLSTM(input_size=300, hidden_size=300, output_size=100)\n",
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "#device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval() \n",
    "k_values = [1, 5, 10, 20, 50]\n",
    "accuracy_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            for i in range(len(outputs)):\n",
    "                distances = []\n",
    "                for j in range(len(labels)):\n",
    "                    distances.append(hyporbolic_distance(outputs[i], labels[j]))\n",
    "                # get the indices of the k nearest neighbors\n",
    "                indices = np.argsort(distances)[:k]\n",
    "                # get the labels of the k nearest neighbors\n",
    "                nearest_neighbors = labels[indices]\n",
    "                # check if the true label is among the k nearest neighbors\n",
    "                true_label = labels[i]\n",
    "                if true_label in nearest_neighbors:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "        accuracy = correct / total\n",
    "        accuracy_values.append(accuracy)\n",
    "        \n",
    "for i, accuracy in zip(k_values, accuracy_values):\n",
    "    print(f\"Accuracy for k={i}: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15149002 -0.00588327 -0.01927167 ...  0.13347381  0.05824211\n",
      "  -0.110452  ]\n",
      " [ 0.09172472  0.01436075  0.04251928 ... -0.04174102  0.03248358\n",
      "  -0.01895724]\n",
      " [ 0.03682062  0.01093031  0.01620699 ...  0.02730098  0.00170489\n",
      "  -0.02050288]\n",
      " ...\n",
      " [ 0.13538103  0.09132892 -0.00368471 ...  0.16022784 -0.01432297\n",
      "   0.05173496]\n",
      " [-0.0598892   0.07564677 -0.04869265 ... -0.0221441   0.00432681\n",
      "   0.13782363]\n",
      " [ 0.02208643  0.06257834 -0.00210662 ...  0.08658007 -0.00262798\n",
      "  -0.01696791]]\n",
      "(64, 100)\n",
      "[[ 0.19665678  0.02667253 -0.02934773 ...  0.18277912  0.03209405\n",
      "  -0.08987681]\n",
      " [ 0.18238278  0.15877901  0.08966684 ...  0.02679526 -0.00069893\n",
      "  -0.07635263]\n",
      " [ 0.04590896 -0.00326635  0.1301228  ... -0.10906892  0.13626042\n",
      "  -0.28794193]\n",
      " ...\n",
      " [ 0.1141592   0.08765475  0.00559242 ...  0.09552231 -0.05993672\n",
      "   0.04217599]\n",
      " [-0.07532855  0.06801189 -0.0207578  ...  0.01642261 -0.00719422\n",
      "   0.10086993]\n",
      " [ 0.08028945  0.04673268  0.05113677 ...  0.03378233 -0.10373269\n",
      "  -0.0321836 ]]\n",
      "(64, 100)\n",
      "0.3595875122028344\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "model = BiLSTM(input_size=300, hidden_size=300, output_size=100)\n",
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "#device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#get predicted label from the model and calculate the distance between the predicted label and the true label\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        print(outputs)\n",
    "        print(outputs.shape)\n",
    "        labels = labels.cpu().numpy()\n",
    "        print(labels)\n",
    "        print(labels.shape)\n",
    "        distance = hyporbolic_distance(outputs, labels)\n",
    "        print(distance)\n",
    "        #stop after one iteration\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
