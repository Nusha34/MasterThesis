{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from gensim.models.poincare import PoincareModel\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(\"/workspaces/master_thesis/word2vec_pubmed.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7357295 , -1.3917009 , -3.0318334 , -2.357155  ,  1.1424465 ,\n",
       "       -0.02943132, -0.39708394, -1.142466  ,  0.25679728, -0.8578018 ,\n",
       "       -1.3225051 ,  0.357423  ,  0.4506469 , -1.465964  ,  0.83961564,\n",
       "        0.8856604 ,  2.7216253 ,  1.0778252 , -3.4893215 ,  0.166895  ,\n",
       "        0.16774897, -1.8470141 ,  0.27980718,  0.21232131,  1.3932807 ,\n",
       "       -0.26180035,  2.4073963 , -1.935196  , -2.011056  , -0.7977714 ,\n",
       "        0.84900767,  2.1022625 ,  0.48991847,  1.5260231 , -1.2548038 ,\n",
       "       -0.06538101, -2.814732  , -0.78244203,  3.327612  ,  0.47770292,\n",
       "        0.45387393, -1.0638123 , -0.6918469 , -2.8515708 ,  1.0283729 ,\n",
       "       -0.19389367,  2.589224  ,  1.3255198 ,  3.061081  ,  0.4531893 ,\n",
       "       -2.9245992 , -0.18764217, -0.24312156, -1.6939746 , -0.1621548 ,\n",
       "        0.15502797, -2.6995914 ,  1.5194799 , -3.0585392 ,  2.5285625 ,\n",
       "        1.0150543 ,  1.0662335 , -1.7643276 , -1.4378964 , -0.92283463,\n",
       "        3.3171194 , -1.7529407 , -2.2593923 , -1.3944848 ,  0.8701171 ,\n",
       "       -0.25234774,  0.16926123, -2.5197163 , -1.4649761 ,  1.1209991 ,\n",
       "       -0.9505807 ,  1.708411  , -0.40490413,  2.3445468 , -0.35216767,\n",
       "       -3.2266192 , -0.03642507,  0.04236065, -1.0482116 ,  0.60604125,\n",
       "        2.801469  ,  0.6157135 ,  0.16256987, -0.37902558,  1.7618409 ,\n",
       "       -1.0593445 , -0.4425322 , -1.2853239 ,  1.0867039 ,  0.37078422,\n",
       "        0.10226439,  0.5401169 , -1.1366138 , -0.60857224,  0.14846691,\n",
       "       -2.3958983 , -0.86920136,  0.8329554 , -2.166745  , -1.4125066 ,\n",
       "        0.16764227, -0.25936562, -2.3283725 , -2.655831  ,  4.3194895 ,\n",
       "        0.7654762 , -2.088732  , -0.31893104, -0.51874006, -2.4790385 ,\n",
       "        0.8880159 , -1.9650003 , -0.36453095, -0.19209957, -0.4162079 ,\n",
       "       -0.01539066,  1.1602464 , -2.3323884 , -1.2571578 , -1.3474635 ,\n",
       "       -0.43720627,  1.6834807 , -2.5083158 ,  1.8655512 ,  1.6355444 ,\n",
       "        1.0416183 ,  2.0347495 ,  0.9593262 ,  1.4262145 ,  1.5945715 ,\n",
       "       -2.339561  ,  2.1160953 , -1.0638533 , -0.3040811 , -0.6643168 ,\n",
       "       -2.355402  ,  2.923428  , -0.4064297 ,  1.1706431 , -1.3718181 ,\n",
       "       -1.6828173 , -0.06695727,  0.5292918 ,  0.45881858, -3.2175055 ,\n",
       "       -1.1698549 ,  0.2531511 , -0.6929788 ,  1.2297274 ,  0.95451576,\n",
       "       -2.4342294 ,  2.1437778 ,  0.9509921 , -0.22131714,  2.43138   ,\n",
       "        1.1671946 ,  0.14104368, -1.5016408 , -1.6132296 , -3.8575613 ,\n",
       "        1.9684795 , -3.0096138 , -1.7854533 , -2.6040373 ,  0.48449433,\n",
       "       -0.5762978 ,  1.2880557 ,  0.56980115, -0.12921605,  1.1367437 ,\n",
       "        1.736069  ,  1.818919  ,  0.81951445,  0.13942046, -0.13387944,\n",
       "        0.79745156,  0.67361087, -0.27389905, -1.2690353 , -1.6104711 ,\n",
       "        2.0558062 , -1.7421268 ,  0.6364859 , -1.110245  ,  1.910716  ,\n",
       "       -2.495731  , -0.16670805, -1.5957444 , -1.3430592 , -1.5788566 ,\n",
       "       -3.254942  ,  0.41595528,  1.2635847 ,  0.12107041,  1.1148648 ,\n",
       "        1.2060553 ,  0.17001012, -0.796594  , -1.5487902 ,  0.81666   ,\n",
       "        0.2518632 ,  0.05421848, -1.1303372 ,  2.463629  ,  2.4916697 ,\n",
       "        1.2380341 ,  1.6239974 , -0.16879746, -2.2866619 , -0.06377321,\n",
       "       -0.07411711,  1.8278371 ,  0.8402302 , -3.4964702 ,  3.4353158 ,\n",
       "        0.9591865 ,  0.8701623 , -1.0447518 ,  4.479976  ,  0.4335019 ,\n",
       "       -4.693462  ,  1.1825355 , -0.87849885,  2.0189052 ,  0.6765587 ,\n",
       "       -0.0568004 ,  0.7918628 , -0.7700992 , -0.7962183 ,  2.5165532 ,\n",
       "        1.380481  , -0.25282773,  0.5693313 , -2.9547143 , -1.014065  ,\n",
       "       -0.40960783, -1.6065093 , -0.01034601,  0.35377783,  2.2143288 ,\n",
       "       -1.2091951 ,  1.02235   ,  0.262552  ,  0.07541446, -0.12266333,\n",
       "       -0.94243854,  2.256549  ,  0.92099947,  0.97368175, -0.17021808,\n",
       "        0.40887246,  0.7586029 , -0.00676408, -1.9415317 , -1.22037   ,\n",
       "        1.0158764 ,  0.537308  ,  0.17073348, -1.7972949 ,  0.9115918 ,\n",
       "       -1.9335847 ,  1.57252   ,  1.1169057 , -2.0166209 , -2.158601  ,\n",
       "        0.7256744 , -0.30296564, -0.03230766,  1.724073  , -2.1345723 ,\n",
       "       -0.10491892, -3.6209676 ,  0.9668008 , -2.5518553 , -0.24527806,\n",
       "       -2.7526588 ,  1.1741465 ,  1.5292807 ,  1.2005813 , -2.0442138 ,\n",
       "        3.4370847 , -2.58816   ,  1.8987492 ,  0.31163508, -0.9623018 ,\n",
       "        0.15364647,  0.06344905, -0.54840696, -0.22905017, -1.2555155 ,\n",
       "       -1.0491987 ,  1.9668791 ,  2.0687897 , -1.4119031 ,  5.8607535 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv['reproductive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_model=PoincareModel.load('/workspaces/master_thesis/poincare/poincare_20d_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606241537673438"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_model.kv.similarity('necrospermia', 'male reproduct find')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_with_fallback(model, word, size, random_state=None):\n",
    "    try:\n",
    "        return model[word]  # Use .wv to access KeyedVectors\n",
    "    except KeyError:\n",
    "        # Return a random vector if the word is not in the model\n",
    "        if random_state is None:\n",
    "            random_state = np.random.default_rng()\n",
    "        return random_state.normal(0, 1, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return 1 - cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_with_fallback(model, word, size, random_state=None):\n",
    "    try:\n",
    "        return model[word]  # Use .wv to access KeyedVectors\n",
    "    except KeyError:\n",
    "        # Return a random vector if the word is not in the model\n",
    "        if random_state is None:\n",
    "            random_state = np.random.default_rng()\n",
    "        return random_state.normal(0, 1, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences into words\n",
    "def tokenize_sentence(sentence):\n",
    "    return word_tokenize(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average vector representation for a sentence\n",
    "def sentence_vector_word2vec(sentence, model, random_state=None):\n",
    "    tokens = tokenize_sentence(sentence)\n",
    "    vectors = [get_embedding_with_fallback(model, token, word2vec_model.vector_size) for token in tokens]\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fused similarity between sentences\n",
    "def fused_sentence_similarity(sentence1, sentence2, alpha=0.5, random_state=None):\n",
    "    # Get Word2Vec average embeddings\n",
    "    word2vec_vec1 = sentence_vector_word2vec(sentence1, word2vec_model.wv, random_state)\n",
    "    word2vec_vec2 = sentence_vector_word2vec(sentence2, word2vec_model.wv, random_state)\n",
    "\n",
    "    # Get Poincare average embeddings\n",
    "    poincare_vec1 = poincare_model.kv[sentence1]\n",
    "\n",
    "    poincare_vec2 = poincare_model.kv[sentence2]\n",
    "\n",
    "    # Calculate similarities\n",
    "    word2vec_similarity = cosine_similarity(word2vec_vec1, word2vec_vec2)\n",
    "    poincare_similarity = cosine_similarity(poincare_vec1, poincare_vec2)\n",
    "\n",
    "    # Fuse the similarities using a weighted average (alpha for Word2Vec, 1-alpha for Poincare)\n",
    "    fused_similarity = alpha * word2vec_similarity + (1 - alpha) * poincare_similarity\n",
    "\n",
    "    return fused_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471074756591261"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_sentence_similarity('necrospermia', 'male reproduct find')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Load pre-trained Word2Vec embeddings\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('word2vec_model.bin', binary=True)\n",
    "\n",
    "# Load pre-trained Poincare embeddings\n",
    "poincare_model = KeyedVectors.load('poincare_model.kv')\n",
    "\n",
    "# Define a function to calculate cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return 1 - cosine(vec1, vec2)\n",
    "\n",
    "# Define a function to normalize Poincare embeddings\n",
    "def normalize_poincare(poincare_vec):\n",
    "    norm = np.linalg.norm(poincare_vec)\n",
    "    return 2 * poincare_vec / (1 + norm**2)\n",
    "\n",
    "# Late fusion of Word2Vec and Poincare embeddings\n",
    "def fused_similarity(word1, word2, alpha=0.5):\n",
    "    # Get Word2Vec embeddings\n",
    "    word2vec_vec1 = word2vec_model[word1]\n",
    "    word2vec_vec2 = word2vec_model[word2]\n",
    "\n",
    "    # Get Poincare embeddings\n",
    "    poincare_vec1 = normalize_poincare(poincare_model[word1])\n",
    "    poincare_vec2 = normalize_poincare(poincare_model[word2])\n",
    "\n",
    "    # Calculate similarities\n",
    "    word2vec_similarity = cosine_similarity(word2vec_vec1, word2vec_vec2)\n",
    "    poincare_similarity = cosine_similarity(poincare_vec1, poincare_vec2)\n",
    "\n",
    "    # Fuse the similarities using a weighted average (alpha for Word2Vec, 1-alpha for Poincare)\n",
    "    fused_similarity = alpha * word2vec_similarity + (1 - alpha) * poincare_similarity\n",
    "\n",
    "    return fused_similarity\n",
    "\n",
    "# Example usage\n",
    "word1 = 'cat'\n",
    "word2 = 'dog'\n",
    "\n",
    "similarity = fused_similarity(word1, word2)\n",
    "print(f\"The fused similarity between '{word1}' and '{word2}' is: {similarity:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ivergny\tArras\n",
    "Avot\tDijon\n",
    "Chabrac\tConfolens\n",
    "Luchem\tLangerwehe\n",
    "\n",
    "congenital rectal fissure\tlesion of rectum\n",
    "Necrospermia\tMale reproductive finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def preprocessing(sample):\n",
    "    sample = sample.lower()\n",
    "    stemmer = PorterStemmer()\n",
    "    token_list = []\n",
    "    doc = nlp(sample)\n",
    "    token_list = [stemmer.stem(token.text)\n",
    "            for token in doc\n",
    "            if not token.is_stop and not token.is_punct\n",
    "        ]\n",
    "    text = \" \".join(token_list)\n",
    "    return text  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'necrospermia'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing('Necrospermia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male reproduct find'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing('Male reproductive finding')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
